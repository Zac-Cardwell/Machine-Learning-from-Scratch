{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5910367",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "Naive Bayes is a classification technique based on Bayes’ Theorem. assuming that the presence of a particular feature in a class is unrelated to the presence of any other feature. Naïve Bayes classifier is a supervised machine learning algorithm used for classification tasks such as text classification, spam filtering, and sentiment analysis. It belongs to the family of generative learning algorithms, which means that it models the distribution of inputs for a given class or category.\n",
    "\n",
    "Bayes theorem is based on the probability of a hypothesis, given the data and some prior knowledge. The naive Bayes classifier assumes that all features in the input data are independent of each other, which is often not true in real-world scenarios. However, despite this simplifying assumption, the naive Bayes classifier is widely used because of its efficiency and good performance in many real-world applications.\n",
    "\n",
    "Bayes theorem is stated as:\n",
    "    P(class|data) = (P(data|class) * P(class)) / P(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baf1b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import seed\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56aa16f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('..\\\\Datasets\\\\iris.csv')\n",
    "data = data.drop(['Id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95847fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[\"Species\"] == \"Iris-setosa\", \"Species\"] = 0\n",
    "data.loc[data[\"Species\"] == \"Iris-versicolor\", \"Species\"] = 1\n",
    "data.loc[data[\"Species\"] == \"Iris-virginica\", \"Species\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d76a98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_class(x):\n",
    "    setosa = x.loc[data['Species'] == 0]\n",
    "    versicolor = x.loc[data['Species'] == 1]\n",
    "    virginica  = x.loc[data['Species'] == 2]\n",
    "    return [setosa, versicolor, virginica]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b892a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarie(x):    \n",
    "    summaries = dict()\n",
    "    temp = list()\n",
    "    x = sep_class(x)\n",
    "    for i in range(len(x)):\n",
    "        temp = list()\n",
    "        for target, valuez in x[i].items():\n",
    "            temp.append((valuez.mean(), valuez.std(), len(valuez)))\n",
    "        temp.pop(-1)\n",
    "        summaries[i] = temp\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3515f381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c9f6a97",
   "metadata": {},
   "source": [
    "# Gaussian Probability Density Function\n",
    "\n",
    "Calculating the probability of observing a given real-value can be difficult. One way to circumvent this is to assume, naïvely, that values are drawn from a distribution, such as a bell curve or Gaussian distribution.\n",
    "\n",
    "A Gaussian distribution can be summarized using only the mean and the standard deviation, making it possible to estimate the probability of a given value using the *Gaussian Probability Distribution Function* (or Gaussian PDF). The Gaussian PDF can be calculated as:\n",
    "\n",
    "    f(x) = (1 / sqrt(2 * PI) * sigma) * exp(-((x-mean)^2 / (2 * sigma^2)))\n",
    "    \n",
    "Where sigma is the standard deviation for x, mean is the mean for x and PI is the value of pi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5488d8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PDF(x, mean, std):\n",
    "    e = np.exp(-((x-mean)**2 / (2 * std**2 )))\n",
    "    return (1 / (np.sqrt(2 * np.pi) * std)) * e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d30117",
   "metadata": {},
   "source": [
    "# Class Probabilities\n",
    "\n",
    "Probabilities are calculated separately for each class, requiring that we first calculate the probability that a new piece of data belongs to the first class, then calculate probabilities that it belongs to the second class, and so on for all the classes. The probability that a piece of data belongs to a class is calculated as:\n",
    "    P(class|data) = P(X|class) * P(class)\n",
    "The division has been removed to simplify the calculation making the result no longer strictly a probability of the data belonging to a class. Now, the calculation for the class that results in the largest value will be taken as the prediction.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e791f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_probabilities(summaries, row):\n",
    "    total_rows = sum([summaries[label][0][2] for label in summaries])\n",
    "    probabilities = dict()\n",
    "    for class_value, class_summaries in summaries.items():\n",
    "         probabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\n",
    "    for i in range(len(class_summaries)):\n",
    "        mean, stdev, count = class_summaries[i]\n",
    "        probabilities[class_value] *= calculate_probability(row[i], mean, stdev)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a55951",
   "metadata": {},
   "source": [
    "#  k-fold cross-validation\n",
    "\n",
    "The algorithm will be evaluted using k-fold cross-validation. Since the dataset being used has 150 rows, the number of folds will be set to 5 giving each class 30 rows each. k-folds helps to estimate how the model is expected to perform in general when used to make predictions on data not used during the training of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2db6d5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    copy = dataset.copy()\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for _ in range(n_folds):\n",
    "        temp = list()\n",
    "        while len(temp) < fold_size:\n",
    "            ind = randrange(len(copy))\n",
    "            temp.append(copy.iloc[ind])\n",
    "            copy.drop(copy.index[ind])\n",
    "        temp = pd.DataFrame(temp)\n",
    "        dataset_split.append(temp)\n",
    "    return dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8640414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, yhat):\n",
    "    correct = 0\n",
    "    for i in range(len(yhat)):\n",
    "        if y[i] == yhat[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(y)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15301618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_probabilities(summaries, row):\n",
    "    \n",
    "    total_rows = sum([summaries[label][0][2] for label in summaries])\n",
    "    probabilities = dict()\n",
    "    for class_value, class_summaries in summaries.items():\n",
    "        \n",
    "        probabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\n",
    "        for i in range(len(class_summaries)):\n",
    "            \n",
    "            mean, std, count = class_summaries[i]\n",
    "            probabilities[class_value] *= PDF(row[i], mean, std)\n",
    "            \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec568f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_algorithm(dataset, n_folds, *args):\n",
    "    folds = kfold(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for i in range(len(folds)):\n",
    "        train_set = list(folds)\n",
    "        train_set.pop(i)\n",
    "        train_set = pd.concat(i for i in train_set)\n",
    "        test_set = list()\n",
    "        for j in range(len(folds[i])):\n",
    "            copy = folds[i].iloc[j].copy()\n",
    "            test_set.append(copy)\n",
    "            copy[-1] = None\n",
    "            predicted = naive_bayes(train_set, test_set, *args)\n",
    "            actual = [folds[i]['Species'].iloc[k] for k in range(len(folds[i]))]\n",
    "        acc = accuracy(actual, predicted)\n",
    "        scores.append(acc)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87aa1fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(summaries, row):\n",
    "    probabilities = calculate_class_probabilities(summaries, row)\n",
    "    best_label, best_prob = None, -1.0\n",
    "    for class_value, probability in probabilities.items():\n",
    "        if best_label is None or probability > best_prob:\n",
    "            best_prob = probability\n",
    "            best_label = class_value\n",
    "    return best_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70f661eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(train, test):\n",
    "    summarize = summarie(train)\n",
    "    predictions = list()\n",
    "    for row in test:\n",
    "        output = predict(summarize, row)\n",
    "        predictions.append(output)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dca9229",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = evaluate_algorithm(data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90bdac67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [96.66666666666667, 100.0, 86.66666666666667, 90.0, 96.66666666666667]\n",
      "Mean Accuracy: 94.000%\n"
     ]
    }
   ],
   "source": [
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
